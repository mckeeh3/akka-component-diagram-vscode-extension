<!-- <nav> -->
- [Akka](../index.html)
- [Understanding](index.html)
- [Foundational AI concepts (video)](ai-concepts-video.html)

<!-- </nav> -->

# Foundational AI concepts (video)

Vectors, embeddings and Retrieval-Augmented Generation (RAG) are core concepts behind modern AI systems, especially those involving large language models (LLMs). Whether you’re just beginning your journey into AI or brushing up on terminology that’s increasingly appearing in development workflows, this is a great place to start.

The following video is an informal walkthrough of foundational AI concepts that underpin tools like ChatGPT, RAG and semantic search.

Topics covered in the video include:

- What vectors are and why they’re foundational to AI
- How embeddings turn human input into machine-readable vectors
- The role of vector distance and similarity metrics (e.g., Euclidean vs. cosine)
- How vector databases support semantic search
- The RAG pattern for enriching LLM prompts
- Why prompt structure, token count, and caching all matter
- How concepts like agency and stateful workflows connect to agentic AI and Akka

<!-- <footer> -->
<!-- <nav> -->
[Endpoints](grpc-vs-http-endpoints.html) [AI Agents](ai-agents.html)
<!-- </nav> -->

<!-- </footer> -->

<!-- <aside> -->

<!-- </aside> -->